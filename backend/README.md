# Londoolink AI Backend

An intelligent agent backend that securely tracks and links your digital life, ensuring you never miss what truly matters.

## ğŸ—ï¸ Current Implementation Status

### âœ… **Phase 0: Foundation (COMPLETED)**
- [x] Project structure with `uv` package management
- [x] FastAPI application with proper configuration
- [x] Health check endpoint
- [x] Development server setup

### âœ… **Phase 1: Security & Authentication (COMPLETED)**
- [x] User registration and login system
- [x] JWT token authentication
- [x] Password hashing with bcrypt
- [x] AES encryption for sensitive credentials
- [x] Protected API endpoints
- [x] SQLite database with User model

### âœ… **Phase 2: AI Brain (COMPLETED)**
- [x] ChromaDB vector database setup
- [x] RAG pipeline for semantic search
- [x] LangChain agent orchestration
- [x] AI-powered daily briefings
- [x] Multi-agent system (Email Triage, Calendar Analysis, Master Prioritization)
- [x] Document analysis and semantic search endpoints

### ğŸ“‹ **Phase 3: Data Ingestion (PENDING)**
- [ ] Email ingestion endpoints
- [ ] Calendar ingestion endpoints
- [ ] n8n workflow integration
- [ ] OAuth2 flow for Google services

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- [uv](https://github.com/astral-sh/uv) package manager
- Docker and Docker Compose

### 1. Setup Database

```bash
# Start PostgreSQL with Docker Compose
docker-compose up -d postgres

# Wait for database to be ready (check health)
docker-compose ps

# Initialize database tables
uv run python init_db.py
```

### 2. Setup Environment

```bash
# Clone and navigate to backend directory
cd backend

# Install dependencies (already done if you followed setup)
uv sync

# Initialize database tables
uv run python init_db.py
```

### 3. Start Development Server

```bash
# Start the FastAPI server
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at:
- **API Base**: http://localhost:8000
- **Interactive Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ“š API Endpoints

### Authentication
- `POST /api/v1/auth/register` - Register new user
- `POST /api/v1/auth/login` - Login and get JWT token

### Agent (Protected)
- `GET /api/v1/agent/health` - Health check
- `GET /api/v1/agent/users/me` - Get current user info
- `GET /api/v1/agent/briefing/daily` - Get AI-powered daily briefing
- `GET /api/v1/agent/rag/stats` - Get RAG pipeline statistics
- `POST /api/v1/agent/rag/search` - Perform semantic search
- `POST /api/v1/agent/analyze/document` - Analyze document with AI

### Ingestion (Protected)
- `POST /api/v1/ingest/email` - Ingest email data into RAG pipeline
- `POST /api/v1/ingest/calendar` - Ingest calendar data into RAG pipeline
- `POST /api/v1/ingest/generic` - Ingest generic message/document data
- `DELETE /api/v1/ingest/documents` - Delete user documents

## ğŸ”§ Configuration

### Environment Variables

The application uses these environment variables (with development defaults):

```bash
# JWT Configuration
SECRET_KEY="dev-secret-key-change-in-production"
JWT_ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Encryption (auto-generated for dev)
ENCRYPTION_KEY="<auto-generated-32-byte-hex>"

# Database (PostgreSQL)
DATABASE_URL="postgresql+psycopg2://londoolink:londoolink123@localhost:5432/londoolink_db"

# AI Configuration (Groq is primary provider)
GROQ_API_KEY="gsk-dev-placeholder"
OPENAI_API_KEY="sk-dev-placeholder"

# ChromaDB
CHROMA_DB_PATH="./chroma_db"

# Environment
ENVIRONMENT="development"
```

### Production Configuration

For production, create a `.env` file:

```bash
cp .env.example .env
# Edit .env with your production values
```

**Important**: Generate secure keys for production:
```bash
# Generate SECRET_KEY
openssl rand -hex 32

# Generate ENCRYPTION_KEY
python -c "import os; print(os.urandom(32).hex())"
```

## ğŸ—ï¸ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py         # Agent & briefing endpoints
â”‚   â”‚   â”‚   â””â”€â”€ ingest.py        # Data ingestion endpoints
â”‚   â”‚   â””â”€â”€ api.py               # Main API router
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py            # Application configuration
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py              # Database engine & base
â”‚   â”‚   â””â”€â”€ session.py           # Database session management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ user.py              # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ user.py              # User Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ token.py             # JWT token schemas
â”‚   â”‚   â””â”€â”€ message.py           # Message/ingestion schemas
â”‚   â”œâ”€â”€ security/                # Security modules
â”‚   â”‚   â”œâ”€â”€ jwt.py               # JWT token handling (PyJWT)
â”‚   â”‚   â”œâ”€â”€ password.py          # Password hashing (Argon2/bcrypt)
â”‚   â”‚   â”œâ”€â”€ encryption.py        # AES encryption (Fernet)
â”‚   â”‚   â”œâ”€â”€ utils.py             # Security utilities
â”‚   â”‚   â””â”€â”€ validator.py         # Security configuration validator
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ coordinator.py       # Main AI coordinator
â”‚   â”‚   â”œâ”€â”€ tools.py             # Shared agent tools
â”‚   â”‚   â”œâ”€â”€ agents/              # Specialized AI agents
â”‚   â”‚   â”‚   â”œâ”€â”€ email_agent.py   # Email analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ calendar_agent.py # Calendar analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ social_agent.py  # Social media analysis
â”‚   â”‚   â”‚   â””â”€â”€ priority_agent.py # Master prioritization
â”‚   â”‚   â””â”€â”€ rag/                 # RAG pipeline components
â”‚   â”‚       â”œâ”€â”€ pipeline.py      # Main RAG pipeline
â”‚   â”‚       â”œâ”€â”€ embeddings.py    # Ollama embeddings
â”‚   â”‚       â”œâ”€â”€ vector_store.py  # ChromaDB operations
â”‚   â”‚       â””â”€â”€ chunker.py       # Text chunking
â”‚   â””â”€â”€ main.py                  # FastAPI application entry point
â”œâ”€â”€ init_db.py                   # Database initialization script
â”œâ”€â”€ docker-compose.yml           # PostgreSQL & pgAdmin setup
â”œâ”€â”€ init-scripts/                # Database initialization SQL scripts
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ db_setup.sh              # Database setup helper script
â”œâ”€â”€ pyproject.toml               # Project dependencies & config
â”œâ”€â”€ .env.example                 # Environment variables template
â””â”€â”€ README.md                    # This file
```

## ğŸ§ª Testing the API

### 1. Register a User
```bash
curl -X POST "http://localhost:8000/api/v1/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "testpassword123"
  }'
```

### 2. Login to Get Token
```bash
curl -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "testpassword123"
  }'
```

### 3. Access Protected Endpoint
```bash
curl -X GET "http://localhost:8000/api/v1/agent/users/me" \
  -H "Authorization: Bearer <your-jwt-token>"
```

## ğŸ”„ Development Workflow

### Adding New Dependencies
```bash
# Add a new dependency
uv add package-name

# Add development dependency
uv add --dev package-name
```

### Database Management
```bash
# Start/stop PostgreSQL
docker-compose up -d postgres
docker-compose down

# View database logs
docker-compose logs postgres

# Access database directly
docker-compose exec postgres psql -U londoolink -d londoolink_db

# After modifying models, recreate tables
uv run python init_db.py

# Access pgAdmin (if started with --profile admin)
# http://localhost:5050
# Email: admin@londoolink.com, Password: admin123
```

### Code Formatting
```bash
# Format code
uv run black app/
uv run isort app/
```

## ğŸš€ Next Development Steps

### Phase 2: AI Brain Implementation
1. **Set up ChromaDB**:
   ```bash
   # ChromaDB is already in dependencies
   # Implement app/services/rag_pipeline.py
   ```

2. **Create RAG Pipeline**:
   - Text chunking and embedding
   - Vector storage and retrieval
   - Semantic search functionality

3. **Implement LangChain Agents**:
   - Email triage agent
   - Calendar analysis agent
   - Master prioritization agent

4. **Update Agent Endpoints**:
   - Make `/briefing/daily` return real AI summaries
   - Add agent configuration endpoints

### Phase 3: Data Ingestion
1. **OAuth2 Integration**:
   - Google OAuth flow
   - Secure token storage
   - Token refresh handling

2. **Ingestion Endpoints**:
   - Email processing and storage
   - Calendar event processing
   - Webhook endpoints for n8n

3. **n8n Integration**:
   - Workflow templates
   - API authentication
   - Error handling and retries

## ğŸ› Troubleshooting

### Common Issues

1. **Server won't start - missing dependencies**:
   ```bash
   uv sync
   ```

2. **Database connection errors**:
   ```bash
   # Check if PostgreSQL is running
   docker-compose ps
   
   # Restart PostgreSQL
   docker-compose restart postgres
   
   # Recreate database tables
   uv run python init_db.py
   ```

3. **JWT token errors**:
   - Check if SECRET_KEY is set
   - Verify token format in Authorization header

4. **Import errors**:
   - Ensure you're in the backend directory
   - Check Python path: `uv run python -c "import app; print('OK')"`

### Development Tips

- Use the interactive docs at `/docs` for testing
- Check server logs for detailed error messages
- Use `uv run uvicorn app.main:app --reload` for auto-reload during development

## ğŸ“ License

This project is part of the Londoolink AI system. See the main project LICENSE file for details.

---

**Need help?** Check the main project README or create an issue in the repository.